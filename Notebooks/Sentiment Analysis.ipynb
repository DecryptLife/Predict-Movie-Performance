{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"5627794078534aecb521db45aa15f0d0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6d17d42e0dde421fab2751e98963c444","IPY_MODEL_5b0648c2e3ad4e15b3e1e340256ae7b7","IPY_MODEL_54e3d27667eb4dba8ee34b389b471d93"],"layout":"IPY_MODEL_4f00a688de3541e4bf4c08671dd89afc"}},"6d17d42e0dde421fab2751e98963c444":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_162c01eac0344ff6ba58c12b174d6dfa","placeholder":"​","style":"IPY_MODEL_0a957c3d32b94a81a0fe436049b295de","value":"100%"}},"5b0648c2e3ad4e15b3e1e340256ae7b7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e777f547f2174c01a470c1e8fea2f163","max":50000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_36abc2f8be5d4ab78a774ea799f7de38","value":50000}},"54e3d27667eb4dba8ee34b389b471d93":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12fc33d184e8446d89e8937e4d03e367","placeholder":"​","style":"IPY_MODEL_b8943bf4568d4b49ade238530fd0ca57","value":" 50000/50000 [00:00&lt;00:00, 537326.22it/s]"}},"4f00a688de3541e4bf4c08671dd89afc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"162c01eac0344ff6ba58c12b174d6dfa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a957c3d32b94a81a0fe436049b295de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e777f547f2174c01a470c1e8fea2f163":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36abc2f8be5d4ab78a774ea799f7de38":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"12fc33d184e8446d89e8937e4d03e367":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8943bf4568d4b49ade238530fd0ca57":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Hf-MMFS-YWxN"},"outputs":[],"source":["import pandas as pd\n","import re\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","from sklearn.feature_extraction.text import CountVectorizer\n","from collections import Counter\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from tqdm.auto import tqdm\n","import time"]},{"cell_type":"code","source":["nltk.download('punkt')\n","nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oKF1MSJ4Rv7a","executionInfo":{"status":"ok","timestamp":1683140899240,"user_tz":300,"elapsed":2155,"user":{"displayName":"benson thomas","userId":"09394232633970299196"}},"outputId":"5f4e0298-87a0-497d-bc68-89854186690a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qno4SxN1r0zW","executionInfo":{"status":"ok","timestamp":1683140938798,"user_tz":300,"elapsed":20733,"user":{"displayName":"benson thomas","userId":"09394232633970299196"}},"outputId":"d729509c-c79c-4ac2-f5bc-cdc0ce56a2e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["path = \"/content/gdrive/MyDrive/ML Project/Project Report/\""],"metadata":{"id":"KqJbIHCSBH7Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = pd.read_csv(path+\"/Datasets/IMDB Dataset.csv\")"],"metadata":{"id":"PuMfGGD5NbMA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Cleaning the text**"],"metadata":{"id":"0OLnUsyJB15T"}},{"cell_type":"code","source":["def clean_text(text):\n","    # Remove HTML tags\n","    text = re.sub('<.*?>', '', text)\n","    # Remove non-alphabetic characters and convert to lowercase\n","    text = re.sub('[^a-zA-Z]', ' ', text).lower()\n","    # text = re.sub('(.*?)','',text)\n","    # Tokenize the text\n","    words = nltk.word_tokenize(text)\n","    # Remove stopwords\n","    words = [w for w in words if w not in stopwords.words('english')]\n","    # Stem the words\n","    stemmer = PorterStemmer()\n","    words = [stemmer.stem(w) for w in words]\n","    # Join the words back into a string\n","    text = ' '.join(words)\n","    return text"],"metadata":{"id":"kMeah5ctN1tR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tqdm.pandas()\n","data['cleaned_text'] = data['review'].progress_apply(clean_text)"],"metadata":{"id":"-v2YE4QvBcol"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Loading the cleaned comments**"],"metadata":{"id":"KUZG4YY8CEmJ"}},{"cell_type":"code","source":["data = pd.read_csv(path+\"Datasets/out-2.csv\")"],"metadata":{"id":"MYUHVDyMBdZm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tqdm.pandas()\n","def transform_label(label):\n","  return 1 if label==\"positive\" else 0\n","data['label'] = data['sentiment'].progress_apply(transform_label)\n","data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238,"referenced_widgets":["5627794078534aecb521db45aa15f0d0","6d17d42e0dde421fab2751e98963c444","5b0648c2e3ad4e15b3e1e340256ae7b7","54e3d27667eb4dba8ee34b389b471d93","4f00a688de3541e4bf4c08671dd89afc","162c01eac0344ff6ba58c12b174d6dfa","0a957c3d32b94a81a0fe436049b295de","e777f547f2174c01a470c1e8fea2f163","36abc2f8be5d4ab78a774ea799f7de38","12fc33d184e8446d89e8937e4d03e367","b8943bf4568d4b49ade238530fd0ca57"]},"id":"5N7lLsI7AH3_","executionInfo":{"status":"ok","timestamp":1683141212770,"user_tz":300,"elapsed":248,"user":{"displayName":"benson thomas","userId":"09394232633970299196"}},"outputId":"164fa3af-c7ab-4e7d-fd06-a64fb1f21eaf"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/50000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5627794078534aecb521db45aa15f0d0"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0                                             review sentiment  \\\n","0           0  One of the other reviewers has mentioned that ...  positive   \n","1           1  A wonderful little production. <br /><br />The...  positive   \n","2           2  I thought this was a wonderful way to spend ti...  positive   \n","3           3  Basically there's a family where a little boy ...  negative   \n","4           4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n","\n","                                        cleaned_text  label  \n","0  one review mention watch oz episod hook right ...      1  \n","1  wonder littl product film techniqu unassum old...      1  \n","2  thought wonder way spend time hot summer weeke...      1  \n","3  basic famili littl boy jake think zombi closet...      0  \n","4  petter mattei love time money visual stun film...      1  "],"text/html":["\n","  <div id=\"df-6da7790f-951c-432a-8cc9-851a031e3f2f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","      <th>cleaned_text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>One of the other reviewers has mentioned that ...</td>\n","      <td>positive</td>\n","      <td>one review mention watch oz episod hook right ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n","      <td>positive</td>\n","      <td>wonder littl product film techniqu unassum old...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>I thought this was a wonderful way to spend ti...</td>\n","      <td>positive</td>\n","      <td>thought wonder way spend time hot summer weeke...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Basically there's a family where a little boy ...</td>\n","      <td>negative</td>\n","      <td>basic famili littl boy jake think zombi closet...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n","      <td>positive</td>\n","      <td>petter mattei love time money visual stun film...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6da7790f-951c-432a-8cc9-851a031e3f2f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6da7790f-951c-432a-8cc9-851a031e3f2f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6da7790f-951c-432a-8cc9-851a031e3f2f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["cv = CountVectorizer(max_features = 512)\n","# cv = CountVectorizer()\n","X = cv.fit_transform(data['cleaned_text']).toarray()\n","y = data['sentiment']"],"metadata":{"id":"Pu-V7ceyBdXM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Logistic Regression for Sentiment Analysis**"],"metadata":{"id":"plCl8kdWt9BW"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,shuffle=False)"],"metadata":{"id":"yCCJqYnvBdUZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","\n","model = LogisticRegression(max_iter = 1000)\n","\n","model.fit(X_train, y_train)\n","\n","y_pred = model.predict(X_test)\n","acc = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AR0VAPhFBdR8","executionInfo":{"status":"ok","timestamp":1683068544896,"user_tz":300,"elapsed":2383,"user":{"displayName":"benson thomas","userId":"09394232633970299196"}},"outputId":"3720eb1e-4c97-459d-8d0f-e245393f0b4e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.8474666666666667\n"]}]},{"cell_type":"markdown","source":["**Saving the model**"],"metadata":{"id":"ce9bLsG9CTzD"}},{"cell_type":"code","source":["import pickle\n","filename = 'ohe_model.pkl'\n","\n","with open(filename, 'wb') as fout:\n","    pickle.dump((cv, model), fout)"],"metadata":{"id":"3gp-_9zAEqAB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Sentiment Analysis using LSTM**"],"metadata":{"id":"_7QlCjsytrec"}},{"cell_type":"code","source":["import numpy as np\n","from torch.utils.data import TensorDataset, DataLoader\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable"],"metadata":{"id":"qVbnFpX9vglH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"lN8JgkMyuZu6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X,y = data['cleaned_text'].values, data['sentiment'].values\n"],"metadata":{"id":"a5ztIAdyuSWP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,shuffle=False)"],"metadata":{"id":"WuYU3qifuRPp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tokenize(X_train,y_train,X_test,y_test):\n","    word_list = []\n","\n","    stop_words = set(stopwords.words('english')) \n","    for sent in X_train:\n","        for word in sent.lower().split():\n","            # word = preprocess_string(word)\n","            if word not in stop_words and word != '':\n","                word_list.append(word)\n","  \n","    corpus = Counter(word_list)\n","    # sorting on the basis of most common words\n","    corpus_ = sorted(corpus,key=corpus.get,reverse=True)[:1000]\n","    # creating a dict\n","    onehot_dict = {w:i+1 for i,w in enumerate(corpus_)}\n","    \n","    # tokenize\n","    final_list_train,final_list_test = [],[]\n","    for sent in X_train:\n","            final_list_train.append([onehot_dict[word] for word in sent.lower().split() \n","                                     if word in onehot_dict.keys()])\n","    for sent in X_test:\n","            final_list_test.append([onehot_dict[word] for word in sent.lower().split() \n","                                    if word in onehot_dict.keys()])\n","            \n","    encoded_train = [1 if label =='positive' else 0 for label in y_train]  \n","    encoded_test = [1 if label =='positive' else 0 for label in y_test] \n","    return np.array(final_list_train, dtype=\"object\"), np.array(encoded_train),np.array(final_list_test), np.array(encoded_test),onehot_dict"],"metadata":{"id":"ElP07bgWtrC4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train,y_train,x_test,y_test,vocab = tokenize(X_train,y_train,X_test,y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hVJj0Fc5vnO9","executionInfo":{"status":"ok","timestamp":1683141603063,"user_tz":300,"elapsed":3800,"user":{"displayName":"benson thomas","userId":"09394232633970299196"}},"outputId":"30c4ccca-61fc-4bbe-8f63-d1e6006f243d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-14-727b7abff01c>:28: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  return np.array(final_list_train, dtype=\"object\"), np.array(encoded_train),np.array(final_list_test), np.array(encoded_test),onehot_dict\n"]}]},{"cell_type":"code","source":["print(f'Length of vocabulary is {len(vocab)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8nK5jmN7wBas","executionInfo":{"status":"ok","timestamp":1683141608676,"user_tz":300,"elapsed":108,"user":{"displayName":"benson thomas","userId":"09394232633970299196"}},"outputId":"73b4675b-b558-4456-b509-321324084245"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Length of vocabulary is 1000\n"]}]},{"cell_type":"code","source":["def padding_(sentences, seq_len):\n","    features = np.zeros((len(sentences), seq_len),dtype=int)\n","    for ii, review in enumerate(sentences):\n","        if len(review) != 0:\n","            features[ii, -len(review):] = np.array(review)[:seq_len]\n","    return features"],"metadata":{"id":"Y_1qCBDWwOLb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#we have very less number of reviews with length > 500.\n","#So we will consideronly those below it.\n","x_train_pad = padding_(x_train,500)\n","x_test_pad = padding_(x_test,500)"],"metadata":{"id":"d0FoDos7wQtW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create Tensor datasets\n","train_data = TensorDataset(torch.from_numpy(x_train_pad), torch.from_numpy(y_train))\n","valid_data = TensorDataset(torch.from_numpy(x_test_pad), torch.from_numpy(y_test))\n","\n","# dataloaders\n","batch_size = 50\n","\n","# make sure to SHUFFLE your data\n","train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n","valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)"],"metadata":{"id":"Yd5ce3k-wUGK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# obtain one batch of training data\n","dataiter = iter(train_loader)\n","sample_x, sample_y = next(iter(train_loader))\n","\n","print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n","print('Sample input: \\n', sample_x)\n","print('Sample input: \\n', sample_y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GLoua3lPwsXj","executionInfo":{"status":"ok","timestamp":1683141680728,"user_tz":300,"elapsed":102,"user":{"displayName":"benson thomas","userId":"09394232633970299196"}},"outputId":"dcd902c7-fcbd-48c3-aa01-3693556c7457"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample input size:  torch.Size([50, 500])\n","Sample input: \n"," tensor([[  0,   0,   0,  ...,  16, 198,  18],\n","        [  0,   0,   0,  ..., 527,  53, 199],\n","        [  0,   0,   0,  ...,  28,  13, 760],\n","        ...,\n","        [  0,   0,   0,  ..., 679, 671,  70],\n","        [  0,   0,   0,  ...,  18,  70, 557],\n","        [  0,   0,   0,  ..., 698, 177,  70]])\n","Sample input: \n"," tensor([1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n","        0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n","        0, 1])\n"]}]},{"cell_type":"code","source":["# function to predict accuracy\n","def acc(pred,label):\n","    pred = torch.round(pred.squeeze())\n","    return torch.sum(pred == label.squeeze()).item()"],"metadata":{"id":"i_o7EDIaFrr_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","class SentimentRNN(nn.Module):\n","    def __init__(self,no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5):\n","        super(SentimentRNN,self).__init__()\n"," \n","        self.output_dim = output_dim\n","        self.hidden_dim = hidden_dim\n"," \n","        self.no_layers = no_layers\n","        self.vocab_size = vocab_size\n","    \n","        # embedding and LSTM layers\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        \n","        #lstm\n","        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim,\n","                           num_layers=no_layers, batch_first=True)\n","        \n","        \n","        # dropout layer\n","        self.dropout = nn.Dropout(0.3)\n","    \n","        # linear and sigmoid layer\n","        self.fc = nn.Linear(self.hidden_dim, output_dim)\n","        self.sig = nn.Sigmoid()\n","        \n","    def forward(self,x,hidden):\n","        batch_size = x.size(0)\n","        # embeddings and lstm_out\n","        embeds = self.embedding(x)  # shape: B x S x Feature   since batch = True\n","        #print(embeds.shape)  #[50, 500, 1000]\n","        lstm_out, hidden = self.lstm(embeds, hidden)\n","        \n","        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim) \n","        \n","        # dropout and fully connected layer\n","        out = self.dropout(lstm_out)\n","        out = self.fc(out)\n","        \n","        # sigmoid function\n","        sig_out = self.sig(out)\n","        \n","        # reshape to be batch_size first\n","        sig_out = sig_out.view(batch_size, -1)\n","\n","        sig_out = sig_out[:, -1] # get last batch of labels\n","        \n","        # return last sigmoid output and hidden state\n","        return sig_out, hidden\n","        \n","        \n","        \n","    def init_hidden(self, batch_size):\n","        ''' Initializes hidden state '''\n","        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n","        # initialized to zero, for hidden state and cell state of LSTM\n","        h0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n","        c0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n","        hidden = (h0,c0)\n","        return hidden"],"metadata":{"id":"OpxnVhu2Gz-_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["no_layers = 2\n","vocab_size = len(vocab) + 1 #extra 1 for padding\n","embedding_dim = 64\n","output_dim = 1\n","hidden_dim = 256\n","\n","\n","model = SentimentRNN(no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5)\n","\n","#moving to gpu\n","model.to(device)\n","\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oJS5UeVxG4nw","executionInfo":{"status":"ok","timestamp":1683141718377,"user_tz":300,"elapsed":9257,"user":{"displayName":"benson thomas","userId":"09394232633970299196"}},"outputId":"eba45672-409a-48cc-ad85-b1ebdb1048f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["SentimentRNN(\n","  (embedding): Embedding(1001, 64)\n","  (lstm): LSTM(64, 256, num_layers=2, batch_first=True)\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (fc): Linear(in_features=256, out_features=1, bias=True)\n","  (sig): Sigmoid()\n",")\n"]}]},{"cell_type":"code","source":["learning_rate = 0.001\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"],"metadata":{"id":"3VxvHXrIGC2z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clip = 5\n","epochs = 5 \n","valid_loss_min = np.Inf\n","# train for some number of epochs\n","epoch_tr_loss,epoch_vl_loss = [],[]\n","epoch_tr_acc,epoch_vl_acc = [],[]\n","\n","for epoch in range(epochs):\n","    train_losses = []\n","    train_acc = 0.0\n","    model.train()\n","    # initialize hidden state \n","    h = model.init_hidden(batch_size)\n","    for inputs, labels in train_loader:\n","        \n","        inputs, labels = inputs.to(device), labels.to(device)   \n","        # Creating new variables for the hidden state, otherwise\n","        # we'd backprop through the entire training history\n","        h = tuple([each.data for each in h])\n","        \n","        model.zero_grad()\n","        output,h = model(inputs,h)\n","        \n","        # calculate the loss and perform backprop\n","        loss = criterion(output.squeeze(), labels.float())\n","        loss.backward()\n","        train_losses.append(loss.item())\n","        # calculating accuracy\n","        accuracy = acc(output,labels)\n","        train_acc += accuracy\n","        #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n","        nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        optimizer.step()\n"," \n","    \n","        \n","    val_h = model.init_hidden(batch_size)\n","    val_losses = []\n","    val_acc = 0.0\n","    model.eval()\n","    for inputs, labels in valid_loader:\n","            val_h = tuple([each.data for each in val_h])\n","\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            output, val_h = model(inputs, val_h)\n","            val_loss = criterion(output.squeeze(), labels.float())\n","\n","            val_losses.append(val_loss.item())\n","            \n","            accuracy = acc(output,labels)\n","            val_acc += accuracy\n","            \n","    epoch_train_loss = np.mean(train_losses)\n","    epoch_val_loss = np.mean(val_losses)\n","    epoch_train_acc = train_acc/len(train_loader.dataset)\n","    epoch_val_acc = val_acc/len(valid_loader.dataset)\n","    epoch_tr_loss.append(epoch_train_loss)\n","    epoch_vl_loss.append(epoch_val_loss)\n","    epoch_tr_acc.append(epoch_train_acc)\n","    epoch_vl_acc.append(epoch_val_acc)\n","    print(f'Epoch {epoch+1}') \n","    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n","    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n","    if epoch_val_loss <= valid_loss_min:\n","        torch.save(model.state_dict(), 'saved_model.pt')\n","        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n","        valid_loss_min = epoch_val_loss\n","    print(25*'==')\n","    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2zOe0g64HFr5","executionInfo":{"status":"ok","timestamp":1683069653594,"user_tz":300,"elapsed":291493,"user":{"displayName":"benson thomas","userId":"09394232633970299196"}},"outputId":"2fb9d310-5280-468e-b5eb-ff7964a31da6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","train_loss : 0.6837761270999908 val_loss : 1.4686259472370147\n","train_accuracy : 54.15714285714286 val_accuracy : 50.06666666666667\n","Validation loss decreased (inf --> 1.468626).  Saving model ...\n","==================================================\n","Epoch 2\n","train_loss : 0.4816354472083705 val_loss : 0.35993853042523066\n","train_accuracy : 77.09428571428572 val_accuracy : 84.44\n","Validation loss decreased (1.468626 --> 0.359939).  Saving model ...\n","==================================================\n","Epoch 3\n","train_loss : 0.3399895536473819 val_loss : 0.3295093301186959\n","train_accuracy : 85.45142857142856 val_accuracy : 86.14\n","Validation loss decreased (0.359939 --> 0.329509).  Saving model ...\n","==================================================\n","Epoch 4\n","train_loss : 0.3052210304566792 val_loss : 0.32481164346138636\n","train_accuracy : 87.09142857142858 val_accuracy : 86.42\n","Validation loss decreased (0.329509 --> 0.324812).  Saving model ...\n","==================================================\n","Epoch 5\n","train_loss : 0.28127304433711936 val_loss : 0.314989915539821\n","train_accuracy : 88.25714285714285 val_accuracy : 86.78666666666666\n","Validation loss decreased (0.324812 --> 0.314990).  Saving model ...\n","==================================================\n"]}]},{"cell_type":"markdown","source":["**Saving the LSTM Model**"],"metadata":{"id":"j352l8nREWjH"}},{"cell_type":"code","source":["model_save_name = 'saved_model_lstm_86.pt'\n","path = F\"/content/gdrive/My Drive/ML Project/{model_save_name}\"\n","model.load_state_dict(torch.load(path))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5MklGwEbLP1V","executionInfo":{"status":"ok","timestamp":1683069710828,"user_tz":300,"elapsed":427,"user":{"displayName":"benson thomas","userId":"09394232633970299196"}},"outputId":"42116f35-733f-4d1f-97c7-5715b6fc51dc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["def predict_text(text):\n","        word_seq = np.array([vocab[word] for word in text.split() \n","                         if word in vocab.keys()])\n","        word_seq = np.expand_dims(word_seq,axis=0)\n","        pad =  torch.from_numpy(padding_(word_seq,500))\n","        inputs = pad.to(device)\n","        batch_size = 1\n","        h = model.init_hidden(batch_size)\n","        h = tuple([each.data for each in h])\n","        output, h = model(inputs, h)\n","        return(output.item())"],"metadata":{"id":"ngkY2--yLwZT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["index = 60\n","print(data['cleaned_text'][index])\n","print('='*70)\n","print(f'Actual sentiment is  : {data[\"sentiment\"][index]}')\n","print('='*70)\n","pro = predict_text(data['cleaned_text'][index])\n","status = \"positive\" if pro > 0.5 else \"negative\"\n","pro = (1 - pro) if status == \"negative\" else pro\n","print(f'Predicted sentiment is {status} with a probability of {pro}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UwsejcgbLoKC","executionInfo":{"status":"ok","timestamp":1683069716037,"user_tz":300,"elapsed":248,"user":{"displayName":"benson thomas","userId":"09394232633970299196"}},"outputId":"55b69529-7722-42b9-eee1-2890c2a26e8a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["happen basic solid plausibl premis decent talent cast somewher movi lose actual never realli got go littl excit find angi realli pregnant find steve martin talent person usual bring lot movi dread entir charact even close import movi make longer realli would like see interact main charact kate angi mayb tri pure comedi unfortun mayb drama comed element think movi could funni sinc actress quit funni way sit think numer scenario would riot\n","======================================================================\n","Actual sentiment is  : negative\n","======================================================================\n","Predicted sentiment is negative with a probability of 0.8907629922032356\n"]}]},{"cell_type":"code","source":["guard_gal_comments = pd.read_csv('/content/gdrive/MyDrive/ML Project/movie_comments/movieCommentsCleaned/movieCommentsCleaned1.csv')"],"metadata":{"id":"QmCyR_isOOBa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["guard_gal_comments.head(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"ZPTpnjxUPyi3","executionInfo":{"status":"ok","timestamp":1683069727202,"user_tz":300,"elapsed":103,"user":{"displayName":"benson thomas","userId":"09394232633970299196"}},"outputId":"ba2fce2b-4be6-4d19-f111-a8d513a4f458"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0           ID                                           comments  \\\n","0           0  KIpGKumxiGg                  M. Night better not fuck this up.   \n","1           1  KIpGKumxiGg        The window thing made me laugh ha ha ha T_T   \n","2           2  KIpGKumxiGg    Anyone else think Kevin was Michael Fassbender?   \n","3           3  KIpGKumxiGg  I was on board until he started &quot;altering...   \n","4           4  KIpGKumxiGg             My god professor what happened to you?   \n","\n","                                  cleaned_comments  \n","0                                night better fuck  \n","1                 window thing made laugh ha ha ha  \n","2           anyon els think kevin michael fassbend  \n","3  board start quot alter bodi chemistri mind quot  \n","4                             god professor happen  "],"text/html":["\n","  <div id=\"df-9002cae4-c677-4945-ba09-3d637ba4ff9d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>ID</th>\n","      <th>comments</th>\n","      <th>cleaned_comments</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>KIpGKumxiGg</td>\n","      <td>M. Night better not fuck this up.</td>\n","      <td>night better fuck</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>KIpGKumxiGg</td>\n","      <td>The window thing made me laugh ha ha ha T_T</td>\n","      <td>window thing made laugh ha ha ha</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>KIpGKumxiGg</td>\n","      <td>Anyone else think Kevin was Michael Fassbender?</td>\n","      <td>anyon els think kevin michael fassbend</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>KIpGKumxiGg</td>\n","      <td>I was on board until he started &amp;quot;altering...</td>\n","      <td>board start quot alter bodi chemistri mind quot</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>KIpGKumxiGg</td>\n","      <td>My god professor what happened to you?</td>\n","      <td>god professor happen</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9002cae4-c677-4945-ba09-3d637ba4ff9d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9002cae4-c677-4945-ba09-3d637ba4ff9d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9002cae4-c677-4945-ba09-3d637ba4ff9d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["def classify_comments(comments):\n","\n","  for comment in comments:\n","    pro = predict_text(comment)\n","    status = \"positive\" if pro > 0.4 else \"negative\"\n","    pro = (1 - pro) if status == \"negative\" else pro\n","    print(f'Predicted sentiment is {status} with a probability of {pro}')\n"],"metadata":{"id":"ibHPLDDAP-qJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gog_comments = guard_gal_comments['cleaned_comments'].values[:5]\n","classify_comments(gog_comments)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UAIUN6-NQgBL","executionInfo":{"status":"ok","timestamp":1683069732182,"user_tz":300,"elapsed":91,"user":{"displayName":"benson thomas","userId":"09394232633970299196"}},"outputId":"af42d346-a50c-47f5-e855-c2c34f839fd0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted sentiment is negative with a probability of 0.6350912153720856\n","Predicted sentiment is positive with a probability of 0.6268795728683472\n","Predicted sentiment is positive with a probability of 0.5481216907501221\n","Predicted sentiment is negative with a probability of 0.7138091027736664\n","Predicted sentiment is positive with a probability of 0.47551047801971436\n"]}]}]}